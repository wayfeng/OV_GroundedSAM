{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c60959-9e80-469a-8e34-f6f34602b73b",
   "metadata": {},
   "source": [
    "# Benchmarking ViT with OpenVINO\n",
    "\n",
    "Pytorch source code and models from: https://github.com/lukemelas/PyTorch-Pretrained-ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb890e35-d37b-4986-a38f-44b270eaaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9fa0723-7318-403f-86fc-cb4f82d55dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb27784-554b-47e0-8b21-9143ca6f704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186d91d1-ad55-4cac-8cde-644ab9025505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9d0eda-dd0a-4f2e-b9b9-d2a81e188443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 384, 384])\n"
     ]
    }
   ],
   "source": [
    "img = T.Compose([\n",
    "    T.Resize((384, 384)), \n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])(Image.open('./assets/cat_dog.jpeg')).unsqueeze(0)\n",
    "print(img.shape) # torch.Size([1, 3, 384, 384])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cee55a1-d1d9-4fd0-8a30-b79e7b401a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88221f9e-99eb-49b4-a45f-76518cd57f22",
   "metadata": {},
   "source": [
    "## Convert to OpenVINO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a5aa4-1d9e-4d14-bc33-6b3c1c166a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.tools import mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45d16ca7-1953-43fd-bc5d-83267fa6d84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023.2.0-12538-e7c1344d3c3\n"
     ]
    }
   ],
   "source": [
    "import openvino as ov\n",
    "print(ov.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e49ff6-849e-4409-b966-1e3d852840b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b308a5-4600-4496-91d5-efceed042392",
   "metadata": {},
   "source": [
    "### Model Base-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e9317aa-3c03-4c55-bd31-2f66405e06da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'b_16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71c8ef28-7d62-4e29-8f5f-473754b201b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('B_16_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bae92746-4eef-4182-be2a-39492fedf60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino import Core\n",
    "core = Core()\n",
    "ov_model_read = core.read_model(ov_vit_path)\n",
    "ov_model = core.compile_model(ov_model_read)\n",
    "results = ov_model.infer_new_request({\"x\": img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4cfbfdf0-1132-49d7-b754-a87238da5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = results.to_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ee54b-6cbd-4a0f-9ca2-8d9817fecca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "inputs = torch.randn([1,3,input_size,input_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2698a116-2535-4f84-87e3-b80aeed36228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/ov/PyTorch-Pretrained-ViT/pytorch_pretrained_vit/transformer.py:16: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n"
     ]
    }
   ],
   "source": [
    "ov_vit_path = Path(f\"./models/vit_{model_id}_384.xml\")\n",
    "if not ov_vit_path.exists():\n",
    "    ov_model = mo.convert_model(model, example_input=img, compress_to_fp16=True)\n",
    "    ov.save_model(ov_model, ov_vit_path)\n",
    "else:\n",
    "    print(f\"{ov_vit_path} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f73614c-f775-46a6-ac85-8f7cd00e8ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] GPU\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 25.40 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 4868.20 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model0\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 1\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   MODEL_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_HOST_TASK_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_THROTTLE: Priority.MEDIUM\n",
      "[ INFO ]   GPU_ENABLE_LOOP_UNROLLING: True\n",
      "[ INFO ]   GPU_DISABLE_WINOGRAD_CONVOLUTION: False\n",
      "[ INFO ]   CACHE_DIR: \n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.LATENCY\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   COMPILATION_NUM_THREADS: 128\n",
      "[ INFO ]   NUM_STREAMS: 1\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float16'>\n",
      "[ INFO ]   DEVICE_ID: 0\n",
      "[ INFO ]   EXECUTION_DEVICES: ['OCL_GPU.0']\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'x'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'x' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 1 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in full mode (inputs filling are included in measurement loop).\n",
      "[ INFO ] First inference took 1329.20 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['OCL_GPU.0']\n",
      "[ INFO ] Count:            5659 iterations\n",
      "[ INFO ] Duration:         60011.28 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        10.11 ms\n",
      "[ INFO ]    Average:       10.52 ms\n",
      "[ INFO ]    Min:           9.61 ms\n",
      "[ INFO ]    Max:           81.06 ms\n",
      "[ INFO ] Throughput:   94.30 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m ./models/vit_b_16.xml -data_shape \"x[1,3,384,384]\" -hint latency -d GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd266753-25ed-4afb-9f42-6ae430d541b9",
   "metadata": {},
   "source": [
    "### Model Base-patch32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddeaaf48-8ece-4f57-8199-08e764fcafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'b_32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "293ab2c6-45df-4f66-af2c-f2b7d920ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_32_imagenet1k.pth\" to /home/wayne/.cache/torch/hub/checkpoints/B_32_imagenet1k.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 337M/337M [01:04<00:00, 5.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('B_32_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "054884de-ea3f-4314-ac86-e7dfbbfec43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/ov/PyTorch-Pretrained-ViT/pytorch_pretrained_vit/transformer.py:16: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n"
     ]
    }
   ],
   "source": [
    "ov_vit_path = Path(f\"./models/vit_{model_id}.xml\")\n",
    "if not ov_vit_path.exists():\n",
    "    ov_model = mo.convert_model(model, example_input=img, compress_to_fp16=True)\n",
    "    ov.save_model(ov_model, ov_vit_path)\n",
    "else:\n",
    "    print(f\"{ov_vit_path} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "064a28c5-d289-4a12-b9f6-f8f6ab643f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] GPU\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 25.40 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 42735.86 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model12\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 1\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   MODEL_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_HOST_TASK_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_THROTTLE: Priority.MEDIUM\n",
      "[ INFO ]   GPU_ENABLE_LOOP_UNROLLING: True\n",
      "[ INFO ]   GPU_DISABLE_WINOGRAD_CONVOLUTION: False\n",
      "[ INFO ]   CACHE_DIR: \n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.LATENCY\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   COMPILATION_NUM_THREADS: 128\n",
      "[ INFO ]   NUM_STREAMS: 1\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float16'>\n",
      "[ INFO ]   DEVICE_ID: 0\n",
      "[ INFO ]   EXECUTION_DEVICES: ['OCL_GPU.0']\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'x'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'x' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 1 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in full mode (inputs filling are included in measurement loop).\n",
      "[ INFO ] First inference took 1346.31 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['OCL_GPU.0']\n",
      "[ INFO ] Count:            5596 iterations\n",
      "[ INFO ] Duration:         60009.46 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        6.58 ms\n",
      "[ INFO ]    Average:       10.64 ms\n",
      "[ INFO ]    Min:           6.40 ms\n",
      "[ INFO ]    Max:           17.04 ms\n",
      "[ INFO ] Throughput:   93.25 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m ./models/vit_b_32.xml -data_shape \"x[1,3,384,384]\" -hint latency -d GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c79482-c9d9-4fc0-9201-53c8d84a6125",
   "metadata": {},
   "source": [
    "### Model large-patch16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e3ab6aae-e913-439b-98e7-78e4d395e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'l_16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edde0502-e591-4ed9-b728-4d99118706e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/L_16_imagenet1k.pth\" to /home/wayne/.cache/torch/hub/checkpoints/L_16_imagenet1k.pth\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 1.14G/1.14G [01:40<00:00, 12.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('L_16_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42b6028f-a278-4274-bf84-9c91c4e38607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/ov/PyTorch-Pretrained-ViT/pytorch_pretrained_vit/transformer.py:16: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  shape[shape.index(-1)] = int(x.size(-1) / -np.prod(shape))\n"
     ]
    }
   ],
   "source": [
    "ov_vit_path = Path(f\"./models/vit_{model_id}.xml\")\n",
    "if not ov_vit_path.exists():\n",
    "    ov_model = mo.convert_model(model, example_input=img, compress_to_fp16=True)\n",
    "    ov.save_model(ov_model, ov_vit_path)\n",
    "else:\n",
    "    print(f\"{ov_vit_path} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bfcbc75-1dd9-4136-988b-ee0e35572e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ INFO ] GPU\n",
      "[ INFO ] Build ................................. 2023.2.0-12538-e7c1344d3c3\n",
      "[ INFO ] \n",
      "[ INFO ] \n",
      "[Step 3/11] Setting device configuration\n",
      "[Step 4/11] Reading model files\n",
      "[ INFO ] Loading model files\n",
      "[ INFO ] Read model took 45.34 ms\n",
      "[ INFO ] Original model I/O parameters:\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 5/11] Resizing model to match image sizes and given batch\n",
      "[ INFO ] Model batch size: 1\n",
      "[Step 6/11] Configuring input of the model\n",
      "[ INFO ] Model inputs:\n",
      "[ INFO ]     x (node: x) : f32 / [...] / [?,?,?,?]\n",
      "[ INFO ] Model outputs:\n",
      "[ INFO ]     ***NO_NAME*** (node: __module.fc/aten::linear/Add) : f32 / [...] / [?,1000]\n",
      "[Step 7/11] Loading the model to the device\n",
      "[ INFO ] Compile model took 5838.19 ms\n",
      "[Step 8/11] Querying optimal runtime parameters\n",
      "[ INFO ] Model:\n",
      "[ INFO ]   NETWORK_NAME: Model15\n",
      "[ INFO ]   OPTIMAL_NUMBER_OF_INFER_REQUESTS: 1\n",
      "[ INFO ]   PERF_COUNT: False\n",
      "[ INFO ]   MODEL_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_HOST_TASK_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_PRIORITY: Priority.MEDIUM\n",
      "[ INFO ]   GPU_QUEUE_THROTTLE: Priority.MEDIUM\n",
      "[ INFO ]   GPU_ENABLE_LOOP_UNROLLING: True\n",
      "[ INFO ]   GPU_DISABLE_WINOGRAD_CONVOLUTION: False\n",
      "[ INFO ]   CACHE_DIR: \n",
      "[ INFO ]   PERFORMANCE_HINT: PerformanceMode.LATENCY\n",
      "[ INFO ]   EXECUTION_MODE_HINT: ExecutionMode.PERFORMANCE\n",
      "[ INFO ]   COMPILATION_NUM_THREADS: 128\n",
      "[ INFO ]   NUM_STREAMS: 1\n",
      "[ INFO ]   PERFORMANCE_HINT_NUM_REQUESTS: 0\n",
      "[ INFO ]   INFERENCE_PRECISION_HINT: <Type: 'float16'>\n",
      "[ INFO ]   DEVICE_ID: 0\n",
      "[ INFO ]   EXECUTION_DEVICES: ['OCL_GPU.0']\n",
      "[Step 9/11] Creating infer requests and preparing input tensors\n",
      "[ WARNING ] No input files were given for input 'x'!. This input will be filled with random values!\n",
      "[ INFO ] Fill input 'x' with random values \n",
      "[Step 10/11] Measuring performance (Start inference asynchronously, 1 inference requests, limits: 60000 ms duration)\n",
      "[ INFO ] Benchmarking in full mode (inputs filling are included in measurement loop).\n",
      "[ INFO ] First inference took 1486.05 ms\n",
      "[Step 11/11] Dumping statistics report\n",
      "[ INFO ] Execution Devices:['OCL_GPU.0']\n",
      "[ INFO ] Count:            2380 iterations\n",
      "[ INFO ] Duration:         60037.57 ms\n",
      "[ INFO ] Latency:\n",
      "[ INFO ]    Median:        24.14 ms\n",
      "[ INFO ]    Average:       25.14 ms\n",
      "[ INFO ]    Min:           23.48 ms\n",
      "[ INFO ]    Max:           291.25 ms\n",
      "[ INFO ] Throughput:   39.64 FPS\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m ./models/vit_l_16.xml -data_shape \"x[1,3,384,384]\" -hint latency -d GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd608842-5f7b-42cc-a9e6-0e13ca5cac09",
   "metadata": {},
   "source": [
    "## Huggingface Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
